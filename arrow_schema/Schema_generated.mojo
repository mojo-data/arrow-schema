# automatically generated by the FlatBuffers compiler, do not modify
import flatbuffers


@value
struct MetadataVersion(EqualityComparable):
    var value: Int16

    #  0.1.0 (October 2016).
    alias V1 = MetadataVersion(0)
    #  0.2.0 (February 2017). Non-backwards compatible with V1.
    alias V2 = MetadataVersion(1)
    #  0.3.0 -> 0.7.1 (May - December 2017). Non-backwards compatible with V2.
    alias V3 = MetadataVersion(2)
    #  >= 0.8.0 (December 2017). Non-backwards compatible with V3.
    alias V4 = MetadataVersion(3)
    #  >= 1.0.0 (July 2020). Backwards compatible with V4 (V5 readers can read V4
    #  metadata and IPC messages). Implementations are recommended to provide a
    #  V4 compatibility mode with V5 format changes disabled.
    #
    #  Incompatible changes between V4 and V5:
    #  - Union buffer layout has changed. In V5, Unions don't have a validity
    #    bitmap buffer.
    alias V5 = MetadataVersion(4)

    fn __eq__(self, other: MetadataVersion) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: MetadataVersion) -> Bool:
        return self.value != other.value


#  Represents Arrow Features that might not have full support
#  within implementations. This is intended to be used in
#  two scenarios:
#   1.  A mechanism for readers of Arrow Streams
#       and files to understand that the stream or file makes
#       use of a feature that isn't supported or unknown to
#       the implementation (and therefore can meet the Arrow
#       forward compatibility guarantees).
#   2.  A means of negotiating between a client and server
#       what features a stream is allowed to use. The enums
#       values here are intented to represent higher level
#       features, additional details maybe negotiated
#       with key-value pairs specific to the protocol.
#
#  Enums added to this list should be assigned power-of-two values
#  to facilitate exchanging and comparing bitmaps for supported
#  features.
@value
struct Feature(EqualityComparable):
    var value: Int64

    #  Needed to make flatbuffers happy.
    alias UNUSED = Feature(0)
    #  The stream makes use of multiple full dictionaries with the
    #  same ID and assumes clients implement dictionary replacement
    #  correctly.
    alias DICTIONARY_REPLACEMENT = Feature(1)
    #  The stream makes use of compressed bodies as described
    #  in Message.fbs.
    alias COMPRESSED_BODY = Feature(2)

    fn __eq__(self, other: Feature) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: Feature) -> Bool:
        return self.value != other.value


@value
struct UnionMode(EqualityComparable):
    var value: Int16

    alias Sparse = UnionMode(0)
    alias Dense = UnionMode(1)

    fn __eq__(self, other: UnionMode) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: UnionMode) -> Bool:
        return self.value != other.value


@value
struct Precision(EqualityComparable):
    var value: Int16

    alias HALF = Precision(0)
    alias SINGLE = Precision(1)
    alias DOUBLE = Precision(2)

    fn __eq__(self, other: Precision) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: Precision) -> Bool:
        return self.value != other.value


@value
struct DateUnit(EqualityComparable):
    var value: Int16

    alias DAY = DateUnit(0)
    alias MILLISECOND = DateUnit(1)

    fn __eq__(self, other: DateUnit) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: DateUnit) -> Bool:
        return self.value != other.value


@value
struct TimeUnit(EqualityComparable):
    var value: Int16

    alias SECOND = TimeUnit(0)
    alias MILLISECOND = TimeUnit(1)
    alias MICROSECOND = TimeUnit(2)
    alias NANOSECOND = TimeUnit(3)

    fn __eq__(self, other: TimeUnit) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: TimeUnit) -> Bool:
        return self.value != other.value


@value
struct IntervalUnit(EqualityComparable):
    var value: Int16

    alias YEAR_MONTH = IntervalUnit(0)
    alias DAY_TIME = IntervalUnit(1)
    alias MONTH_DAY_NANO = IntervalUnit(2)

    fn __eq__(self, other: IntervalUnit) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: IntervalUnit) -> Bool:
        return self.value != other.value


#  ----------------------------------------------------------------------
#  Top-level Type value, enabling extensible type-specific metadata. We can
#  add new logical types to Type without breaking backwards compatibility
@value
struct Type(EqualityComparable):
    var value: UInt8

    alias NONE = Type(0)
    alias Null = Type(1)
    alias Int_ = Type(2)
    alias FloatingPoint = Type(3)
    alias Binary = Type(4)
    alias Utf8 = Type(5)
    alias Bool_ = Type(6)
    alias Decimal = Type(7)
    alias Date = Type(8)
    alias Time = Type(9)
    alias Timestamp = Type(10)
    alias Interval = Type(11)
    alias List_ = Type(12)
    alias Struct_ = Type(13)
    alias Union = Type(14)
    alias FixedSizeBinary = Type(15)
    alias FixedSizeList = Type(16)
    alias Map = Type(17)
    alias Duration = Type(18)
    alias LargeBinary = Type(19)
    alias LargeUtf8 = Type(20)
    alias LargeList = Type(21)
    alias RunEndEncoded = Type(22)
    alias BinaryView = Type(23)
    alias Utf8View = Type(24)
    alias ListView = Type(25)
    alias LargeListView = Type(26)

    fn __eq__(self, other: Type) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: Type) -> Bool:
        return self.value != other.value


#  ----------------------------------------------------------------------
#  Dictionary encoding metadata
#  Maintained for forwards compatibility, in the future
#  Dictionaries might be explicit maps between integers and values
#  allowing for non-contiguous index values
@value
struct DictionaryKind(EqualityComparable):
    var value: Int16

    alias DenseArray = DictionaryKind(0)

    fn __eq__(self, other: DictionaryKind) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: DictionaryKind) -> Bool:
        return self.value != other.value


#  ----------------------------------------------------------------------
#  Endianness of the platform producing the data
@value
struct Endianness(EqualityComparable):
    var value: Int16

    alias Little = Endianness(0)
    alias Big = Endianness(1)

    fn __eq__(self, other: Endianness) -> Bool:
        return self.value == other.value

    fn __ne__(self, other: Endianness) -> Bool:
        return self.value != other.value


#  These are stored in the flatbuffer in the Type union below
@value
struct Null:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Null:
        return Null(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  A Struct_ in the flatbuffer metadata is the same as an Arrow Struct
#  (according to the physical memory layout). We used Struct_ here as
#  Struct is a reserved word in Flatbuffers
@value
struct Struct_:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Struct_:
        return Struct_(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


@value
struct List_:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> List_:
        return List_(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Same as List, but with 64-bit offsets, allowing to represent
#  extremely large data values.
@value
struct LargeList:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> LargeList:
        return LargeList(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Represents the same logical types that List can, but contains offsets and
#  sizes allowing for writes in any order and sharing of child values among
#  list values.
@value
struct ListView:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> ListView:
        return ListView(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Same as ListView, but with 64-bit offsets and sizes, allowing to represent
#  extremely large data values.
@value
struct LargeListView:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> LargeListView:
        return LargeListView(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


@value
struct FixedSizeList:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    #  Number of list items per value
    fn listSize(self) -> Int32:
        return flatbuffers.field[DType.int32](self._buf, int(self._pos), 4, 0)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> FixedSizeList:
        return FixedSizeList(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        listSize: Int32 = 0,
    ) -> flatbuffers.Offset:
        builder.start_object(1)
        if listSize != 0:
            builder.prepend(listSize)
            builder.slot(0)
        return builder.end_object()


#  A Map is a logical nested type that is represented as
#
#  List<entries: Struct<key: K, value: V>>
#
#  In this layout, the keys and values are each respectively contiguous. We do
#  not constrain the key and value types, so the application is responsible
#  for ensuring that the keys are hashable and unique. Whether the keys are sorted
#  may be set in the metadata for this field.
#
#  In a field with Map type, the field has a child Struct field, which then
#  has two children: key type and the second the value type. The names of the
#  child fields may be respectively "entries", "key", and "value", but this is
#  not enforced.
#
#  Map
#  ```text
#    - child[0] entries: Struct
#      - child[0] key: K
#      - child[1] value: V
#  ```
#  Neither the "entries" field nor the "key" field may be nullable.
#
#  The metadata is structured so that Arrow systems without special handling
#  for Map can make Map an alias for List. The "layout" attribute for the Map
#  field must have the same contents as a List.
@value
struct Map:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    #  Set to true if the keys within each value are sorted
    fn keysSorted(self) -> Scalar[DType.bool]:
        return flatbuffers.field[DType.bool](self._buf, int(self._pos), 4, 0)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Map:
        return Map(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        keysSorted: Scalar[DType.bool] = 0,
    ) -> flatbuffers.Offset:
        builder.start_object(1)
        if keysSorted != 0:
            builder.prepend(keysSorted)
            builder.slot(0)
        return builder.end_object()


#  A union is a complex type with children in Field
#  By default ids in the type vector refer to the offsets in the children
#  optionally typeIds provides an indirection between the child offset and the type id
#  for each child `typeIds[offset]` is the id used in the type vector
@value
struct Union:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    fn mode(self) -> UnionMode:
        return flatbuffers.field[DType.int16](self._buf, int(self._pos), 4, 0)

    fn typeIds(self, i: Int) -> Int32:
        return flatbuffers.read[DType.int32](
            self._buf,
            flatbuffers.field_vector(self._buf, int(self._pos), 6) + i * 4,
        )

    fn typeIds_length(self) -> Int:
        return flatbuffers.field_vector_len(self._buf, int(self._pos), 6)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Union:
        return Union(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        mode: UnionMode = UnionMode(0),
        typeIds: List[Int32] = List[Int32](),
    ) -> flatbuffers.Offset:
        var _typeIds: Optional[flatbuffers.Offset] = None
        if len(typeIds) > 0:
            builder.start_vector(4, len(typeIds), 4)
            for o in typeIds.__reversed__():
                builder.prepend(o[])
            _typeIds = builder.end_vector(len(typeIds))

        builder.start_object(2)
        if mode != UnionMode(0):
            builder.prepend(mode.value)
            builder.slot(0)
        if _typeIds is not None:
            builder.prepend(_typeIds.value())
            builder.slot(1)
        return builder.end_object()


@value
struct Int_:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    fn bitWidth(self) -> Int32:
        return flatbuffers.field[DType.int32](self._buf, int(self._pos), 4, 0)

    fn is_signed(self) -> Scalar[DType.bool]:
        return flatbuffers.field[DType.bool](self._buf, int(self._pos), 6, 0)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Int_:
        return Int_(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        bitWidth: Int32 = 0,
        is_signed: Scalar[DType.bool] = 0,
    ) -> flatbuffers.Offset:
        builder.start_object(2)
        if bitWidth != 0:
            builder.prepend(bitWidth)
            builder.slot(0)
        if is_signed != 0:
            builder.prepend(is_signed)
            builder.slot(1)
        return builder.end_object()


@value
struct FloatingPoint:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    fn precision(self) -> Precision:
        return flatbuffers.field[DType.int16](self._buf, int(self._pos), 4, 0)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> FloatingPoint:
        return FloatingPoint(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        precision: Precision = Precision(0),
    ) -> flatbuffers.Offset:
        builder.start_object(1)
        if precision != Precision(0):
            builder.prepend(precision.value)
            builder.slot(0)
        return builder.end_object()


#  Unicode with UTF-8 encoding
@value
struct Utf8:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Utf8:
        return Utf8(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Opaque binary data
@value
struct Binary:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Binary:
        return Binary(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Same as Utf8, but with 64-bit offsets, allowing to represent
#  extremely large data values.
@value
struct LargeUtf8:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> LargeUtf8:
        return LargeUtf8(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Same as Binary, but with 64-bit offsets, allowing to represent
#  extremely large data values.
@value
struct LargeBinary:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> LargeBinary:
        return LargeBinary(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Logically the same as Utf8, but the internal representation uses a view
#  struct that contains the string length and either the string's entire data
#  inline (for small strings) or an inlined prefix, an index of another buffer,
#  and an offset pointing to a slice in that buffer (for non-small strings).
#
#  Since it uses a variable number of data buffers, each Field with this type
#  must have a corresponding entry in `variadicBufferCounts`.
@value
struct Utf8View:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Utf8View:
        return Utf8View(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Logically the same as Binary, but the internal representation uses a view
#  struct that contains the string length and either the string's entire data
#  inline (for small strings) or an inlined prefix, an index of another buffer,
#  and an offset pointing to a slice in that buffer (for non-small strings).
#
#  Since it uses a variable number of data buffers, each Field with this type
#  must have a corresponding entry in `variadicBufferCounts`.
@value
struct BinaryView:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> BinaryView:
        return BinaryView(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


@value
struct FixedSizeBinary:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    #  Number of bytes per value
    fn byteWidth(self) -> Int32:
        return flatbuffers.field[DType.int32](self._buf, int(self._pos), 4, 0)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> FixedSizeBinary:
        return FixedSizeBinary(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        byteWidth: Int32 = 0,
    ) -> flatbuffers.Offset:
        builder.start_object(1)
        if byteWidth != 0:
            builder.prepend(byteWidth)
            builder.slot(0)
        return builder.end_object()


@value
struct Bool_:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Bool_:
        return Bool_(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Contains two child arrays, run_ends and values.
#  The run_ends child array must be a 16/32/64-bit integer array
#  which encodes the indices at which the run with the value in
#  each corresponding index in the values child array ends.
#  Like list/struct types, the value array can be of any type.
@value
struct RunEndEncoded:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> RunEndEncoded:
        return RunEndEncoded(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
    ) -> flatbuffers.Offset:
        builder.start_object(0)
        return builder.end_object()


#  Exact decimal value represented as an integer value in two's
#  complement. Currently only 128-bit (16-byte) and 256-bit (32-byte) integers
#  are used. The representation uses the endianness indicated
#  in the Schema.
@value
struct Decimal:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    #  Total number of decimal digits
    fn precision(self) -> Int32:
        return flatbuffers.field[DType.int32](self._buf, int(self._pos), 4, 0)

    #  Number of digits after the decimal point "."
    fn scale(self) -> Int32:
        return flatbuffers.field[DType.int32](self._buf, int(self._pos), 6, 0)

    #  Number of bits per value. The only accepted widths are 128 and 256.
    #  We use bitWidth for consistency with Int::bitWidth.
    fn bitWidth(self) -> Int32:
        return flatbuffers.field[DType.int32](self._buf, int(self._pos), 8, 128)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Decimal:
        return Decimal(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        precision: Int32 = 0,
        scale: Int32 = 0,
        bitWidth: Int32 = 128,
    ) -> flatbuffers.Offset:
        builder.start_object(3)
        if precision != 0:
            builder.prepend(precision)
            builder.slot(0)
        if scale != 0:
            builder.prepend(scale)
            builder.slot(1)
        if bitWidth != 128:
            builder.prepend(bitWidth)
            builder.slot(2)
        return builder.end_object()


#  Date is either a 32-bit or 64-bit signed integer type representing an
#  elapsed time since UNIX epoch (1970-01-01), stored in either of two units:
#
#  * Milliseconds (64 bits) indicating UNIX time elapsed since the epoch (no
#    leap seconds), where the values are evenly divisible by 86400000
#  * Days (32 bits) since the UNIX epoch
@value
struct Date:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    fn unit(self) -> DateUnit:
        return flatbuffers.field[DType.int16](self._buf, int(self._pos), 4, 1)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Date:
        return Date(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        unit: DateUnit = DateUnit(1),
    ) -> flatbuffers.Offset:
        builder.start_object(1)
        if unit != DateUnit(1):
            builder.prepend(unit.value)
            builder.slot(0)
        return builder.end_object()


#  Time is either a 32-bit or 64-bit signed integer type representing an
#  elapsed time since midnight, stored in either of four units: seconds,
#  milliseconds, microseconds or nanoseconds.
#
#  The integer `bitWidth` depends on the `unit` and must be one of the following:
#  * SECOND and MILLISECOND: 32 bits
#  * MICROSECOND and NANOSECOND: 64 bits
#
#  The allowed values are between 0 (inclusive) and 86400 (=24*60*60) seconds
#  (exclusive), adjusted for the time unit (for example, up to 86400000
#  exclusive for the MILLISECOND unit).
#  This definition doesn't allow for leap seconds. Time values from
#  measurements with leap seconds will need to be corrected when ingesting
#  into Arrow (for example by replacing the value 86400 with 86399).
@value
struct Time:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    fn unit(self) -> TimeUnit:
        return flatbuffers.field[DType.int16](self._buf, int(self._pos), 4, 1)

    fn bitWidth(self) -> Int32:
        return flatbuffers.field[DType.int32](self._buf, int(self._pos), 6, 32)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Time:
        return Time(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        unit: TimeUnit = TimeUnit(1),
        bitWidth: Int32 = 32,
    ) -> flatbuffers.Offset:
        builder.start_object(2)
        if unit != TimeUnit(1):
            builder.prepend(unit.value)
            builder.slot(0)
        if bitWidth != 32:
            builder.prepend(bitWidth)
            builder.slot(1)
        return builder.end_object()


#  Timestamp is a 64-bit signed integer representing an elapsed time since a
#  fixed epoch, stored in either of four units: seconds, milliseconds,
#  microseconds or nanoseconds, and is optionally annotated with a timezone.
#
#  Timestamp values do not include any leap seconds (in other words, all
#  days are considered 86400 seconds long).
#
#  Timestamps with a non-empty timezone
#  ------------------------------------
#
#  If a Timestamp column has a non-empty timezone value, its epoch is
#  1970-01-01 00:00:00 (January 1st 1970, midnight) in the *UTC* timezone
#  (the Unix epoch), regardless of the Timestamp's own timezone.
#
#  Therefore, timestamp values with a non-empty timezone correspond to
#  physical points in time together with some additional information about
#  how the data was obtained and/or how to display it (the timezone).
#
#    For example, the timestamp value 0 with the timezone string "Europe/Paris"
#    corresponds to "January 1st 1970, 00h00" in the UTC timezone, but the
#    application may prefer to display it as "January 1st 1970, 01h00" in
#    the Europe/Paris timezone (which is the same physical point in time).
#
#  One consequence is that timestamp values with a non-empty timezone
#  can be compared and ordered directly, since they all share the same
#  well-known point of reference (the Unix epoch).
#
#  Timestamps with an unset / empty timezone
#  -----------------------------------------
#
#  If a Timestamp column has no timezone value, its epoch is
#  1970-01-01 00:00:00 (January 1st 1970, midnight) in an *unknown* timezone.
#
#  Therefore, timestamp values without a timezone cannot be meaningfully
#  interpreted as physical points in time, but only as calendar / clock
#  indications ("wall clock time") in an unspecified timezone.
#
#    For example, the timestamp value 0 with an empty timezone string
#    corresponds to "January 1st 1970, 00h00" in an unknown timezone: there
#    is not enough information to interpret it as a well-defined physical
#    point in time.
#
#  One consequence is that timestamp values without a timezone cannot
#  be reliably compared or ordered, since they may have different points of
#  reference.  In particular, it is *not* possible to interpret an unset
#  or empty timezone as the same as "UTC".
#
#  Conversion between timezones
#  ----------------------------
#
#  If a Timestamp column has a non-empty timezone, changing the timezone
#  to a different non-empty value is a metadata-only operation:
#  the timestamp values need not change as their point of reference remains
#  the same (the Unix epoch).
#
#  However, if a Timestamp column has no timezone value, changing it to a
#  non-empty value requires to think about the desired semantics.
#  One possibility is to assume that the original timestamp values are
#  relative to the epoch of the timezone being set; timestamp values should
#  then adjusted to the Unix epoch (for example, changing the timezone from
#  empty to "Europe/Paris" would require converting the timestamp values
#  from "Europe/Paris" to "UTC", which seems counter-intuitive but is
#  nevertheless correct).
#
#  Guidelines for encoding data from external libraries
#  ----------------------------------------------------
#
#  Date & time libraries often have multiple different data types for temporal
#  data. In order to ease interoperability between different implementations the
#  Arrow project has some recommendations for encoding these types into a Timestamp
#  column.
#
#  An "instant" represents a physical point in time that has no relevant timezone
#  (for example, astronomical data). To encode an instant, use a Timestamp with
#  the timezone string set to "UTC", and make sure the Timestamp values
#  are relative to the UTC epoch (January 1st 1970, midnight).
#
#  A "zoned date-time" represents a physical point in time annotated with an
#  informative timezone (for example, the timezone in which the data was
#  recorded).  To encode a zoned date-time, use a Timestamp with the timezone
#  string set to the name of the timezone, and make sure the Timestamp values
#  are relative to the UTC epoch (January 1st 1970, midnight).
#
#   (There is some ambiguity between an instant and a zoned date-time with the
#    UTC timezone.  Both of these are stored the same in Arrow.  Typically,
#    this distinction does not matter.  If it does, then an application should
#    use custom metadata or an extension type to distinguish between the two cases.)
#
#  An "offset date-time" represents a physical point in time combined with an
#  explicit offset from UTC.  To encode an offset date-time, use a Timestamp
#  with the timezone string set to the numeric timezone offset string
#  (e.g. "+03:00"), and make sure the Timestamp values are relative to
#  the UTC epoch (January 1st 1970, midnight).
#
#  A "naive date-time" (also called "local date-time" in some libraries)
#  represents a wall clock time combined with a calendar date, but with
#  no indication of how to map this information to a physical point in time.
#  Naive date-times must be handled with care because of this missing
#  information, and also because daylight saving time (DST) may make
#  some values ambiguous or nonexistent. A naive date-time may be
#  stored as a struct with Date and Time fields. However, it may also be
#  encoded into a Timestamp column with an empty timezone. The timestamp
#  values should be computed "as if" the timezone of the date-time values
#  was UTC; for example, the naive date-time "January 1st 1970, 00h00" would
#  be encoded as timestamp value 0.
@value
struct Timestamp:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    fn unit(self) -> TimeUnit:
        return flatbuffers.field[DType.int16](self._buf, int(self._pos), 4, 0)

    #  The timezone is an optional string indicating the name of a timezone,
    #  one of:
    #
    #  * As used in the Olson timezone database (the "tz database" or
    #    "tzdata"), such as "America/New_York".
    #  * An absolute timezone offset of the form "+XX:XX" or "-XX:XX",
    #    such as "+07:30".
    #
    #  Whether a timezone string is present indicates different semantics about
    #  the data (see above).
    fn timezone(self) -> StringRef:
        return flatbuffers.field_string(self._buf, int(self._pos), 6)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Timestamp:
        return Timestamp(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        unit: TimeUnit = TimeUnit(0),
        timezone: Optional[StringRef] = None,
    ) -> flatbuffers.Offset:
        var _timezone: Optional[flatbuffers.Offset] = None
        if timezone is not None:
            _timezone = builder.prepend(timezone.value())
        builder.start_object(2)
        if unit != TimeUnit(0):
            builder.prepend(unit.value)
            builder.slot(0)
        if _timezone is not None:
            builder.prepend(_timezone.value())
            builder.slot(1)
        return builder.end_object()


@value
struct Interval:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    fn unit(self) -> IntervalUnit:
        return flatbuffers.field[DType.int16](self._buf, int(self._pos), 4, 0)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Interval:
        return Interval(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        unit: IntervalUnit = IntervalUnit(0),
    ) -> flatbuffers.Offset:
        builder.start_object(1)
        if unit != IntervalUnit(0):
            builder.prepend(unit.value)
            builder.slot(0)
        return builder.end_object()


@value
struct Duration:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    fn unit(self) -> TimeUnit:
        return flatbuffers.field[DType.int16](self._buf, int(self._pos), 4, 1)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Duration:
        return Duration(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        unit: TimeUnit = TimeUnit(1),
    ) -> flatbuffers.Offset:
        builder.start_object(1)
        if unit != TimeUnit(1):
            builder.prepend(unit.value)
            builder.slot(0)
        return builder.end_object()


#  ----------------------------------------------------------------------
#  user defined key value pairs to add custom metadata to arrow
#  key namespacing is the responsibility of the user
@value
struct KeyValue:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    fn key(self) -> StringRef:
        return flatbuffers.field_string(self._buf, int(self._pos), 4)

    fn value(self) -> StringRef:
        return flatbuffers.field_string(self._buf, int(self._pos), 6)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> KeyValue:
        return KeyValue(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        key: Optional[StringRef] = None,
        value: Optional[StringRef] = None,
    ) -> flatbuffers.Offset:
        var _key: Optional[flatbuffers.Offset] = None
        if key is not None:
            _key = builder.prepend(key.value())
        var _value: Optional[flatbuffers.Offset] = None
        if value is not None:
            _value = builder.prepend(value.value())
        builder.start_object(2)
        if _key is not None:
            builder.prepend(_key.value())
            builder.slot(0)
        if _value is not None:
            builder.prepend(_value.value())
            builder.slot(1)
        return builder.end_object()


@value
struct DictionaryEncoding:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    #  The known dictionary id in the application where this data is used. In
    #  the file or streaming formats, the dictionary ids are found in the
    #  DictionaryBatch messages
    fn id(self) -> Int64:
        return flatbuffers.field[DType.int64](self._buf, int(self._pos), 4, 0)

    #  The dictionary indices are constrained to be non-negative integers. If
    #  this field is null, the indices must be signed int32. To maximize
    #  cross-language compatibility and performance, implementations are
    #  recommended to prefer signed integer types over unsigned integer types
    #  and to avoid uint64 indices unless they are required by an application.
    fn indexType(self) -> Optional[Int_]:
        var o = flatbuffers.field_table(self._buf, int(self._pos), 6)
        if o:
            return Int_(self._buf, o.take())
        return None

    #  By default, dictionaries are not ordered, or the order does not have
    #  semantic meaning. In some statistical, applications, dictionary-encoding
    #  is used to represent ordered categorical data, and we provide a way to
    #  preserve that metadata here
    fn isOrdered(self) -> Scalar[DType.bool]:
        return flatbuffers.field[DType.bool](self._buf, int(self._pos), 8, 0)

    fn dictionaryKind(self) -> DictionaryKind:
        return flatbuffers.field[DType.int16](self._buf, int(self._pos), 10, 0)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> DictionaryEncoding:
        return DictionaryEncoding(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        id: Int64 = 0,
        indexType: Optional[flatbuffers.Offset] = None,
        isOrdered: Scalar[DType.bool] = 0,
        dictionaryKind: DictionaryKind = DictionaryKind(0),
    ) -> flatbuffers.Offset:
        builder.start_object(4)
        if id != 0:
            builder.prepend(id)
            builder.slot(0)
        if indexType is not None:
            builder.prepend(indexType.value())
            builder.slot(1)
        if isOrdered != 0:
            builder.prepend(isOrdered)
            builder.slot(2)
        if dictionaryKind != DictionaryKind(0):
            builder.prepend(dictionaryKind.value)
            builder.slot(3)
        return builder.end_object()


#  ----------------------------------------------------------------------
#  A field represents a named column in a record / row batch or child of a
#  nested type.
@value
struct Field:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    #  Name is not required, in i.e. a List
    fn name(self) -> StringRef:
        return flatbuffers.field_string(self._buf, int(self._pos), 4)

    #  Whether or not this field can contain nulls. Should be true in general.
    fn nullable(self) -> Scalar[DType.bool]:
        return flatbuffers.field[DType.bool](self._buf, int(self._pos), 6, 0)

    fn type_type(self) -> Type:
        return flatbuffers.field[DType.uint8](self._buf, int(self._pos), 8, 0)

    #  This is the type of the decoded value if the field is dictionary encoded.
    fn type_as_Null(self) -> Null:
        return Null(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Int(self) -> Int_:
        return Int_(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_FloatingPoint(self) -> FloatingPoint:
        return FloatingPoint(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Binary(self) -> Binary:
        return Binary(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Utf8(self) -> Utf8:
        return Utf8(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Bool(self) -> Bool_:
        return Bool_(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Decimal(self) -> Decimal:
        return Decimal(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Date(self) -> Date:
        return Date(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Time(self) -> Time:
        return Time(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Timestamp(self) -> Timestamp:
        return Timestamp(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Interval(self) -> Interval:
        return Interval(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_List(self) -> List_:
        return List_(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Struct_(self) -> Struct_:
        return Struct_(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Union(self) -> Union:
        return Union(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_FixedSizeBinary(self) -> FixedSizeBinary:
        return FixedSizeBinary(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_FixedSizeList(self) -> FixedSizeList:
        return FixedSizeList(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Map(self) -> Map:
        return Map(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Duration(self) -> Duration:
        return Duration(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_LargeBinary(self) -> LargeBinary:
        return LargeBinary(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_LargeUtf8(self) -> LargeUtf8:
        return LargeUtf8(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_LargeList(self) -> LargeList:
        return LargeList(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_RunEndEncoded(self) -> RunEndEncoded:
        return RunEndEncoded(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_BinaryView(self) -> BinaryView:
        return BinaryView(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_Utf8View(self) -> Utf8View:
        return Utf8View(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_ListView(self) -> ListView:
        return ListView(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    fn type_as_LargeListView(self) -> LargeListView:
        return LargeListView(
            self._buf,
            flatbuffers.field_table(self._buf, int(self._pos), 10).or_else(0),
        )

    #  Present only if the field is dictionary encoded.
    fn dictionary(self) -> Optional[DictionaryEncoding]:
        var o = flatbuffers.field_table(self._buf, int(self._pos), 12)
        if o:
            return DictionaryEncoding(self._buf, o.take())
        return None

    #  children apply only to nested data types like Struct, List and Union. For
    #  primitive types children will have length 0.
    fn children(self, i: Int) -> Field:
        var start = flatbuffers.field_vector(
            self._buf, int(self._pos), 14
        ) + i * 4
        start += flatbuffers.read_offset_as_int(self._buf, start)
        return Field(self._buf, start)

    fn children_length(self) -> Int:
        return flatbuffers.field_vector_len(self._buf, int(self._pos), 14)

    #  User-defined metadata
    fn custom_metadata(self, i: Int) -> KeyValue:
        var start = flatbuffers.field_vector(
            self._buf, int(self._pos), 16
        ) + i * 4
        start += flatbuffers.read_offset_as_int(self._buf, start)
        return KeyValue(self._buf, start)

    fn custom_metadata_length(self) -> Int:
        return flatbuffers.field_vector_len(self._buf, int(self._pos), 16)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Field:
        return Field(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        name: Optional[StringRef] = None,
        nullable: Scalar[DType.bool] = 0,
        type_type: Type = Type(0),
        type: Optional[flatbuffers.Offset] = None,
        dictionary: Optional[flatbuffers.Offset] = None,
        children: List[flatbuffers.Offset] = List[flatbuffers.Offset](),
        custom_metadata: List[flatbuffers.Offset] = List[flatbuffers.Offset](),
    ) -> flatbuffers.Offset:
        var _name: Optional[flatbuffers.Offset] = None
        if name is not None:
            _name = builder.prepend(name.value())
        var _children: Optional[flatbuffers.Offset] = None
        if len(children) > 0:
            builder.start_vector(4, len(children), 4)
            for o in children.__reversed__():
                builder.prepend(o[])
            _children = builder.end_vector(len(children))

        var _custom_metadata: Optional[flatbuffers.Offset] = None
        if len(custom_metadata) > 0:
            builder.start_vector(4, len(custom_metadata), 4)
            for o in custom_metadata.__reversed__():
                builder.prepend(o[])
            _custom_metadata = builder.end_vector(len(custom_metadata))

        builder.start_object(7)
        if _name is not None:
            builder.prepend(_name.value())
            builder.slot(0)
        if nullable != 0:
            builder.prepend(nullable)
            builder.slot(1)
        if type_type != Type(0):
            builder.prepend(type_type.value)
            builder.slot(2)
        if type is not None:
            builder.prepend(type.value())
            builder.slot(3)
        if dictionary is not None:
            builder.prepend(dictionary.value())
            builder.slot(4)
        if _children is not None:
            builder.prepend(_children.value())
            builder.slot(5)
        if _custom_metadata is not None:
            builder.prepend(_custom_metadata.value())
            builder.slot(6)
        return builder.end_object()


#  ----------------------------------------------------------------------
#  A Buffer represents a single contiguous memory segment
@value
struct Buffer:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    #  The relative offset into the shared memory page where the bytes for this
    #  buffer starts
    fn offset(self) -> Int64:
        return flatbuffers.read[DType.int64](self._buf, int(self._pos) + 0)

    #  The absolute length (in bytes) of the memory buffer. The memory is found
    #  from offset (inclusive) to offset + length (non-inclusive). When building
    #  messages using the encapsulated IPC message, padding bytes may be written
    #  after a buffer, but such padding bytes do not need to be accounted for in
    #  the size here.
    fn length(self) -> Int64:
        return flatbuffers.read[DType.int64](self._buf, int(self._pos) + 8)

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        offset: Int64,
        length: Int64,
    ):
        builder.prep(8, 16)
        builder.prepend[DType.int64](length)
        builder.prepend[DType.int64](offset)


@value
struct BufferVO:
    var length: Int64
    var offset: Int64


#  ----------------------------------------------------------------------
#  A Schema describes the columns in a row batch
@value
struct Schema:
    var _buf: UnsafePointer[UInt8]
    var _pos: Int

    #  endianness of the buffer
    #  it is Little Endian by default
    #  if endianness doesn't match the underlying system then the vectors need to be converted
    fn endianness(self) -> Endianness:
        return flatbuffers.field[DType.int16](self._buf, int(self._pos), 4, 0)

    fn fields(self, i: Int) -> Field:
        var start = flatbuffers.field_vector(
            self._buf, int(self._pos), 6
        ) + i * 4
        start += flatbuffers.read_offset_as_int(self._buf, start)
        return Field(self._buf, start)

    fn fields_length(self) -> Int:
        return flatbuffers.field_vector_len(self._buf, int(self._pos), 6)

    fn custom_metadata(self, i: Int) -> KeyValue:
        var start = flatbuffers.field_vector(
            self._buf, int(self._pos), 8
        ) + i * 4
        start += flatbuffers.read_offset_as_int(self._buf, start)
        return KeyValue(self._buf, start)

    fn custom_metadata_length(self) -> Int:
        return flatbuffers.field_vector_len(self._buf, int(self._pos), 8)

    #  Features used in the stream/file.
    fn features(self, i: Int) -> Feature:
        return flatbuffers.read[DType.int64](
            self._buf,
            flatbuffers.field_vector(self._buf, int(self._pos), 10) + i * 8,
        )

    fn features_length(self) -> Int:
        return flatbuffers.field_vector_len(self._buf, int(self._pos), 10)

    @staticmethod
    fn as_root(buf: UnsafePointer[UInt8]) -> Schema:
        return Schema(buf, flatbuffers.read_offset_as_int(buf, 0))

    @staticmethod
    fn build(
        inout builder: flatbuffers.Builder,
        *,
        endianness: Endianness = Endianness(0),
        fields: List[flatbuffers.Offset] = List[flatbuffers.Offset](),
        custom_metadata: List[flatbuffers.Offset] = List[flatbuffers.Offset](),
        features: List[Feature] = List[Feature](),
    ) -> flatbuffers.Offset:
        var _fields: Optional[flatbuffers.Offset] = None
        if len(fields) > 0:
            builder.start_vector(4, len(fields), 4)
            for o in fields.__reversed__():
                builder.prepend(o[])
            _fields = builder.end_vector(len(fields))

        var _custom_metadata: Optional[flatbuffers.Offset] = None
        if len(custom_metadata) > 0:
            builder.start_vector(4, len(custom_metadata), 4)
            for o in custom_metadata.__reversed__():
                builder.prepend(o[])
            _custom_metadata = builder.end_vector(len(custom_metadata))

        var _features: Optional[flatbuffers.Offset] = None
        if len(features) > 0:
            builder.start_vector(8, len(features), 8)
            for o in features.__reversed__():
                builder.prepend(o[].value)
            _features = builder.end_vector(len(features))

        builder.start_object(4)
        if endianness != Endianness(0):
            builder.prepend(endianness.value)
            builder.slot(0)
        if _fields is not None:
            builder.prepend(_fields.value())
            builder.slot(1)
        if _custom_metadata is not None:
            builder.prepend(_custom_metadata.value())
            builder.slot(2)
        if _features is not None:
            builder.prepend(_features.value())
            builder.slot(3)
        return builder.end_object()
